{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8kbrJBIhudc"
      },
      "source": [
        " ClockWorkLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uajlthdr9As"
      },
      "source": [
        "#!unzip AudioAmp.zip\n",
        "#!unzip clock_work_rnn.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QAEg9H2EMZC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpymcedwGT4E"
      },
      "source": [
        "from cwrnn import ClockworkRNN\n",
        "from __init__ import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwBAcVruJjLm"
      },
      "source": [
        "#3\n",
        "# prepare train data to pass to network\n",
        "# in this part we prepare train data in form:(number of data,time steps,number of data in each time step)\n",
        "from numpy import loadtxt\n",
        "import random\n",
        "import numpy\n",
        "import os\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "min1_in=[]\n",
        "max1_in=[]\n",
        "min1_out=[]\n",
        "max1_out=[]\n",
        "X=[]\n",
        "Y=[]\n",
        "x_plot=[]\n",
        "temp_X=[]\n",
        "temp_Y=[]\n",
        "\n",
        "st='/content/drive/My Drive/High-speed input buffer/Train/'#path to folder of train data\n",
        "\n",
        "for filename in os.listdir(st):\n",
        "    # mydata contains 3 lists which ,each one is a column of data files\n",
        "    # (in data files we have:column 1 as time,column 2 as input ,column3 as output)\n",
        "    # because value of times is not important we ignore them(mydata[0 is ignored])\n",
        "    mydata = loadtxt(st+filename, unpack=True)\n",
        "    my_input=mydata[1]\n",
        "    inputx=[]\n",
        "    # set input in desired form for network:\n",
        "    # input shape should be:(number of data,time steps,number of data in each time step)\n",
        "    # for example we have 12 data,each has 201 time step ,in each time step we have one input\n",
        "    # so input shape is:(12,200,1)..\n",
        "    x_plot.append(mydata[0])\n",
        "\n",
        "    for i in my_input:\n",
        "        inputx.append([i]) # NOTICE:If your data has more than one input,add all of them like:inputx.append([i,j,k])which i,j ,k,.. are inputs of your data\n",
        "\n",
        "    my_output=mydata[2]#select output(2d list in mydata which is 3d column in data file)\n",
        "    # if you normalized inputs,so normalize output like below:\n",
        "    # my_output=(my_output - numpy.min(my_output)) / (numpy.max(my_output) - numpy.min(my_output))\n",
        "    outputy=[]\n",
        "    for i in my_output:\n",
        "        outputy.append([i])\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "    ax0.set_title('Train Data (input1) without normalization')\n",
        "    ax0.plot(mydata[0],my_input,color='b',lw=1)\n",
        "    ax0.grid()\n",
        "    #plt.legend([\"predicted\",\"target value\"])\n",
        "    plt.show()\n",
        "    fig2 = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig2.add_subplot(211)\n",
        "    ax0.set_title('Train Data (output) without normalization')\n",
        "    ax0.plot(mydata[0],my_output,color='b',lw=1)\n",
        "\n",
        "    ax0.grid()\n",
        "    #plt.legend([\"predicted\",\"target value\"])\n",
        "    plt.show()\n",
        "    min1_out.append(numpy.min(my_output))\n",
        "    max1_out.append(numpy.max(my_output))\n",
        "    min1_in.append(numpy.min(my_input))\n",
        "    max1_in.append(numpy.max(my_input))\n",
        "    temp_X.append(my_input)\n",
        "    temp_Y.append(my_output)\n",
        "    X.append(inputx)# train input\n",
        "    Y.append(outputy)#train  output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF08O4okdXS7"
      },
      "source": [
        "#4\n",
        "# implement normalization in range[0,1] on train data\n",
        "from numpy import loadtxt\n",
        "import random\n",
        "import numpy\n",
        "import os\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "mymin1_in=numpy.min(min1_in)\n",
        "mymax1_in=numpy.max(max1_in)\n",
        "mymin1_out=numpy.min(min1_out)\n",
        "mymax1_out=numpy.max(max1_out)\n",
        "input_seq2=temp_X\n",
        "target_seq2=temp_Y\n",
        "X=[]\n",
        "Y=[]\n",
        "for i in range(len(input_seq2)):\n",
        "    input_seq2[i]=(input_seq2[i] - mymin1_in) / (mymax1_in - mymin1_in)\n",
        "    target_seq2[i]=(target_seq2[i] - mymin1_out) / (mymax1_out - mymin1_out)\n",
        "    outputy=[]\n",
        "    for j in target_seq2[i]:\n",
        "        outputy.append([j])\n",
        "    inputx=[]\n",
        "    for j in input_seq2[i]:\n",
        "        inputx.append([j])\n",
        "    X.append(inputx)# train input\n",
        "    Y.append(outputy)#train  output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quE5pn5IJu-A"
      },
      "source": [
        "#5\n",
        "# prepare test data to pass to network\n",
        "# in this part we prepare train data in form:(number of data,time steps,number of data in each time step)\n",
        "from numpy import loadtxt\n",
        "import random\n",
        "import numpy\n",
        "import os\n",
        "from scipy import signal\n",
        "\n",
        "X_test=[]\n",
        "Y_test=[]\n",
        "x_plot_test=[]\n",
        "temp_X2=[]\n",
        "\n",
        "temp_Y2=[]\n",
        "\n",
        "st='/content/drive/My Drive/High-speed input buffer/Test/'#path to folder of train data\n",
        "\n",
        "for filename in os.listdir(st):\n",
        "    # mydata contains 3 lists which ,each one is a column of data files\n",
        "    # (in data files we have:column 1 as time,column 2 as input ,column3 as output)\n",
        "    # because value of times is not important we ignore them(mydata[0 is ignored])\n",
        "    mydata = loadtxt(st+filename, unpack=True)\n",
        "    x_plot_test.append(mydata[0])\n",
        "    my_input=mydata[1]\n",
        "    inputx=[]\n",
        "    # set input in desired form for network:\n",
        "    # input shape should be:(number of data,time steps,number of data in each time step)\n",
        "    # for example we have 12 data,each has 201 time step ,in each time step we have one input\n",
        "    # so input shape is:(12,200,1)..\n",
        "    x_plot.append(mydata[0])\n",
        "\n",
        "    for i in my_input:\n",
        "        inputx.append([i]) # NOTICE:If your data has more than one input,add all of them like:inputx.append([i,j,k])which i,j ,k,.. are inputs of your data\n",
        "\n",
        "    my_output=mydata[2]#select output(2d list in mydata which is 3d column in data file)\n",
        "    # if you normalized inputs,so normalize output like below:\n",
        "    # my_output=(my_output - numpy.min(my_output)) / (numpy.max(my_output) - numpy.min(my_output))\n",
        "    outputy=[]\n",
        "    for i in my_output:\n",
        "        outputy.append([i])\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "    ax0.set_title('Test Data (input1) without normalization')\n",
        "    ax0.plot(mydata[0],my_input,color='b',lw=1)\n",
        "    ax0.grid()\n",
        "    #plt.legend([\"predicted\",\"target value\"])\n",
        "    plt.show()\n",
        "    fig2 = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig2.add_subplot(211)\n",
        "    ax0.set_title('Test Data (output) without normalization')\n",
        "    ax0.plot(mydata[0],my_output,color='b',lw=1)\n",
        "\n",
        "    ax0.grid()\n",
        "    #plt.legend([\"predicted\",\"target value\"])\n",
        "    plt.show()\n",
        "    temp_X2.append(inputx)\n",
        "    temp_Y2.append(outputy)\n",
        "    X_test.append(inputx)# test input\n",
        "    Y_test.append(outputy)#test  output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x9zRcvYdhoX"
      },
      "source": [
        "#6\n",
        "# implement normalization in range[0,1] on test data\n",
        "input_seq22=temp_X2\n",
        "target_seq22=temp_Y2\n",
        "X_test=[]\n",
        "Y_test=[]\n",
        "for i in range(len(input_seq22)):\n",
        "    input_seq22[i]=(input_seq22[i] - mymin1_in) / (mymax1_in - mymin1_in)\n",
        "    target_seq22[i]=(target_seq22[i] - mymin1_out) / (mymax1_out - mymin1_out)\n",
        "    outputy=[]\n",
        "    for j in target_seq22[i]:\n",
        "        outputy.append([j])\n",
        "    inputx=[]\n",
        "    for j in input_seq22[i]:\n",
        "        inputx.append([j])\n",
        "    X_test.append(inputx)# test input\n",
        "    Y_test.append(outputy)#test  output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkKIUyv1NPv0"
      },
      "source": [
        "    #7\n",
        "    # here we interpolate data to all data have same lenght\n",
        "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
        "    import numpy as np\n",
        "    inter_len=80 # number of interpolation (changes data to 200 time step)\n",
        "    X_new=[]\n",
        "    for i in X:\n",
        "        x=range(0,len(i))# number of time steps for original time serie\n",
        "        y=i\n",
        "        interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "        new_x = np.arange(0,len(x),len(x)/inter_len)\n",
        "        new_y = interpolation_function(new_x)\n",
        "        if(len(new_y)>inter_len):\n",
        "            interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "            new_x = np.arange(0,len(x),(len(x)/inter_len)+0.003)\n",
        "            new_y = interpolation_function(new_x)\n",
        "        xx=[]\n",
        "        for j in new_y:\n",
        "          xx.append([j])\n",
        "        X_new.append(xx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u3UqeqfNSx6"
      },
      "source": [
        "    #8\n",
        "    # iterpolate test input data\n",
        "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
        "    import numpy as np\n",
        "    inter_len=80\n",
        "    X_new_test=[]\n",
        "    for i in X_test:\n",
        "        x=range(0,len(i))# number of time steps for original time serie\n",
        "        y=i\n",
        "        interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "        new_x = np.arange(0,len(x),len(x)/inter_len)\n",
        "        new_y = interpolation_function(new_x)\n",
        "        if(len(new_y)>inter_len):\n",
        "            interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "            new_x = np.arange(0,len(x),(len(x)/inter_len)+0.003)\n",
        "            new_y = interpolation_function(new_x)\n",
        "        xx=[]\n",
        "        for j in new_y:\n",
        "          xx.append([j])\n",
        "        X_new_test.append(xx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkIYAuX2NY7E"
      },
      "source": [
        "    #9\n",
        "    # # iterpolate train output data\n",
        "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
        "    import numpy as np\n",
        "    inter_len=80\n",
        "    Y_new=[]\n",
        "    for i in Y:\n",
        "        x=range(0,len(i))# number of time steps for original time serie\n",
        "        y=i\n",
        "        interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "        new_x = np.arange(0,len(x),len(x)/inter_len)\n",
        "        new_y = interpolation_function(new_x)\n",
        "        if(len(new_y)>inter_len):\n",
        "            interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "            new_x = np.arange(0,len(x),(len(x)/inter_len)+0.003)\n",
        "            new_y = interpolation_function(new_x)\n",
        "        xx=[]\n",
        "        for j in new_y:\n",
        "          xx.append([j])\n",
        "        Y_new.append(xx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vpCZYC1NcJD"
      },
      "source": [
        "    #10\n",
        "    # # iterpolate test output data\n",
        "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
        "    import numpy as np\n",
        "    inter_len=80\n",
        "    Y_new_test=[]\n",
        "    for i in Y_test:\n",
        "        x=range(0,len(i))# number of time steps for original time serie\n",
        "        y=i\n",
        "        interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "        new_x = np.arange(0,len(x),len(x)/inter_len)\n",
        "        new_y = interpolation_function(new_x)\n",
        "        if(len(new_y)>inter_len):\n",
        "            interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "            new_x = np.arange(0,len(x),(len(x)/inter_len)+0.003)\n",
        "            new_y = interpolation_function(new_x)\n",
        "        xx=[]\n",
        "        for j in new_y:\n",
        "          xx.append([j])\n",
        "        Y_new_test.append(xx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZBLPMy-Ng_v"
      },
      "source": [
        "    #11\n",
        "    # iterpolate train time\n",
        "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
        "    import numpy as np\n",
        "    inter_len=80\n",
        "    X_plot_new=[]\n",
        "    for i in x_plot:\n",
        "        x=range(0,len(i))# number of time steps for original time serie\n",
        "        y=i\n",
        "        interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "        new_x = np.arange(0,len(x),len(x)/inter_len)\n",
        "        new_y = interpolation_function(new_x)\n",
        "        if(len(new_y)>inter_len):\n",
        "            interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "            new_x = np.arange(0,len(x),(len(x)/inter_len)+0.003)\n",
        "            new_y = interpolation_function(new_x)\n",
        "\n",
        "        X_plot_new.append(new_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOim619LNjtb"
      },
      "source": [
        "    #12\n",
        "    # iterpolate test time\n",
        "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
        "    import numpy as np\n",
        "    inter_len=80\n",
        "    X_plot_new_test=[]\n",
        "    for i in x_plot_test:\n",
        "        x=range(0,len(i))# number of time steps for original time serie\n",
        "        y=i\n",
        "        interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "        new_x = np.arange(0,len(x),len(x)/inter_len)\n",
        "        new_y = interpolation_function(new_x)\n",
        "        if(len(new_y)>inter_len):\n",
        "            interpolation_function = InterpolatedUnivariateSpline(x,y,k=2)\n",
        "            new_x = np.arange(0,len(x),(len(x)/inter_len)+0.003)\n",
        "            new_y = interpolation_function(new_x)\n",
        "\n",
        "        X_plot_new_test.append(new_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi8aRLgsezGa"
      },
      "source": [
        "#13\n",
        "X=X_new\n",
        "Y=Y_new\n",
        "X_test=X_new_test\n",
        "Y_test=Y_new_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Y1bkAyW88o"
      },
      "source": [
        "#14\n",
        "import numpy\n",
        "print(\"train input shape:\",numpy.array(X).shape)\n",
        "print(\"train output shape\",numpy.array(Y).shape)\n",
        "print(\"test input shape:\",numpy.array(X_test).shape)\n",
        "print(\"test output shape\",numpy.array(Y_test).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adamax, RMSprop , Adagrad, Adam, Adadelta\n",
        "#from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "number_timestep=len(X[0])# WHEN GENERATING DATA,TRY TO HAVE REASONABLE TIMESTEPS(LIKE 500 NOT 25000!)\n",
        "number_input=len(X[0][0])\n",
        "\n",
        "aa=40\n",
        "models = tf.keras.Sequential()\n",
        "models.add(layers.SimpleRNN(aa,input_shape=[number_timestep,number_input],return_sequences=True))\n",
        "#models.add(layers.SimpleRNN(aa,input_shape=[number_timestep,number_input],return_sequences=True))\n",
        "#models.add(layers.SimpleRNN(aa,input_shape=[number_timestep,number_input],return_sequences=True))\n",
        "#models.add(layers.SimpleRNN(aa,input_shape=[number_timestep,number_input],return_sequences=True))\n",
        "#models.add(layers.SimpleRNN(aa,input_shape=[number_timestep,number_input],return_sequences=True))\n",
        "models.add(tf.keras.layers.Dense(1))\n",
        "models.summary()"
      ],
      "metadata": {
        "id": "Iy0ZNdewz6cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "#import keras\n",
        "#from keras.models import Sequential\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.optimizers import Adamax, RMSprop, Adagrad\n",
        "#from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# ALL THE STEPS ARE SAME AS MLP,THE ONLY DIFFERENCE IS IN USING RNN.\n",
        "# create network:\n",
        "# input_shape=[number_timestep,number_input]\n",
        "# for example input_shape=[201,1] :means our data have 201 time step and each time step has one value\n",
        "\n",
        "# return_sequences=True: because we are modeling a time serie and need output of all steps\n",
        "# so each step of network must returen output in that step(contrary to classification)\n",
        "# if we have classification problem we set return_sequences=False,to have only output of last step(which is class)\n",
        "\n",
        "#.layers.Dense(1) output layer of each time step has one output\n",
        "# notice:because we we want to predict a float value,so we dont use activation function in last layer\n",
        "number_timestep=len(X[0])# WHEN GENERATING DATA,TRY TO HAVE REASONABLE TIMESTEPS(LIKE 500 NOT 25000!)\n",
        "number_input=len(X[0][0])\n",
        "\n",
        "model = tensorflow.keras.Sequential()\n",
        "\n",
        "\n",
        "model.add(ClockworkRNN(periods=[1, 2, 4, 8, 16, 32, 64, 128],\n",
        "                         units_per_period=5,\n",
        "                         input_shape=(number_timestep, number_input),\n",
        "                         rnn_dtype=tf.keras.layers.LSTM,# **notice change from None to 100**\n",
        "                         output_units=1))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yUzWFOpeA2S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(number_timestep, number_input)"
      ],
      "metadata": {
        "id": "lq0EGHW4lb-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models.compile(loss='huber',\n",
        "               optimizer=RMSprop(learning_rate=0.005),\n",
        "               metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "\n",
        "\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "rE6BSCkTW0sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='huber',\n",
        "              optimizer=RMSprop(learning_rate=0.005),\n",
        "              metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "\n",
        "\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "W1WMIm1Q0p9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "P_qhkdhPw5lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models.load_weights('/content/drive/My Drive/SiRNN/SCPGS.hdf5')"
      ],
      "metadata": {
        "id": "51II06UEh5s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/My Drive/CWLSTM/SCPGS.hdf5')"
      ],
      "metadata": {
        "id": "uXoosGga0xNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint('/content/drive/My Drive/SiRNN/HSIB.hdf5', monitor='val_loss',\n",
        "                                   save_best_only=True, restore_best_weights = True)\n",
        "\n",
        "start_time = time.time()\n",
        "historys = models.fit(X,Y,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=100,\n",
        "                      validation_data=(X_test,Y_test),\n",
        "                      callbacks=[model_checkpoint])\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(\"total training time is:\", total_time)"
      ],
      "metadata": {
        "id": "CTA9NbijyPRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOYBtSmbFXID"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ModelCheckpoint('/content/drive/My Drive/CWLSTM/HSIB.hdf5', monitor='val_loss',\n",
        "                                   save_best_only=True, restore_best_weights = True)\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(X,Y,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=100,\n",
        "                    validation_data=(X_test,Y_test),\n",
        "                    callbacks=[model_checkpoint])\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(\"total training time is:\", total_time)"
      ],
      "metadata": {
        "id": "1DBzRvuu0_so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PqDWHLyeM7H9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "start1 = timer()\n",
        "tainy_predict1 = models(np.array(X[0]), training = False)\n",
        "end1 = timer()\n",
        "print('Direct model runtime :', end1 - start1)"
      ],
      "metadata": {
        "id": "wOqv5Ofcv66c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "start2 = timer()\n",
        "tainy_predict1 = model(np.array(X[0]), training = False)\n",
        "end2 = timer()\n",
        "print('Direct model runtime :', end2 - start2)"
      ],
      "metadata": {
        "id": "tdC7BidpGzhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvEHjpRDtqz8"
      },
      "source": [
        "#18\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(historys.epoch,history.history['loss'],label='loss')\n",
        "plt.plot(historys.epoch,history.history['val_loss'],label='val_loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(historys.epoch,history.history['mean_absolute_percentage_error'], label='mean_absolute_percentage_error')\n",
        "plt.plot(historys.epoch,history.history['val_mean_absolute_percentage_error'],label='val_mean_absolute_percentage_error')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "aZ38_Pq9zqop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cnFghRdtDyR"
      },
      "source": [
        "#19\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(history.epoch,history.history['loss'],label='loss')\n",
        "plt.plot(history.epoch,history.history['val_loss'],label='val_loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(history.epoch,history.history['mean_absolute_percentage_error'], label='mean_absolute_percentage_error')\n",
        "plt.plot(history.epoch,history.history['val_mean_absolute_percentage_error'],label='val_mean_absolute_percentage_error')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdo-e5vYcW6B"
      },
      "source": [
        "models.load_weights('/content/drive/My Drive/SiRNN/HSIB.hdf5')\n",
        "models.save('/content/drive/My Drive/SiRNN/HSIB.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/My Drive/CWLSTM/HSIB.hdf5')\n",
        "model.save('/content/drive/My Drive/CWLSTM/HSIB.hdf5')"
      ],
      "metadata": {
        "id": "4VsuGnum1Lgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiKO2viRxMcw"
      },
      "source": [
        "from inspect import CORO_CLOSED\n",
        "#21\n",
        "# plot the result on train data\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_train=0\n",
        "predicted=models.predict(X)\n",
        "#predicted2=model2.predict(X)\n",
        "#mm=[]\n",
        "for i in range(len(X)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "\n",
        "    bb=numpy.array(Y[i])\n",
        "    aa=numpy.array(predicted[i])\n",
        "#    aa=numpy.array(predicted2[i])\n",
        "    ax0.set_title('Train Data')\n",
        "#    ax0.plot(X_plot_new[i],aa,color='g',marker='None',lw=2,markersize=2,linestyle='-')\n",
        "    ax0.plot(X_plot_new[i],aa,color='r',marker='None',lw=2.5,markersize=2,linestyle='-')\n",
        "    ax0.plot(X_plot_new[i],bb,color='b',lw=2.5,label='Test Data',linestyle=':')\n",
        "\n",
        "\n",
        "    ax0.grid()\n",
        "    plt.legend([\"RNN\",\"Target Value\"])\n",
        "    plt.show()\n",
        "    mse_train+=mean_squared_error(aa,bb)\n",
        "#    mm.append([X_plot_new[i], aa, cc, bb])\n",
        "print('total mse train:',mse_train/len(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import CORO_CLOSED\n",
        "#21\n",
        "# plot the result on train data\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_train=0\n",
        "predicted=model.predict(X)\n",
        "#predicted2=model2.predict(X)\n",
        "#mm=[]\n",
        "for i in range(len(X)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "\n",
        "    bb=numpy.array(Y[i])\n",
        "    cc=numpy.array(predicted[i])\n",
        "#    aa=numpy.array(predicted2[i])\n",
        "    ax0.set_title('Train Data')\n",
        "#    ax0.plot(X_plot_new[i],aa,color='g',marker='None',lw=2,markersize=2,linestyle='-')\n",
        "    ax0.plot(X_plot_new[i],cc,color='r',marker='None',lw=1,markersize=2,linestyle='-')\n",
        "    ax0.plot(X_plot_new[i],bb,color='b',lw=1,label='Test Data',linestyle=':')\n",
        "\n",
        "\n",
        "    ax0.grid()\n",
        "    plt.legend([\"CWLSTM\",\"Target Value\"])\n",
        "    plt.show()\n",
        "    mse_train+=mean_squared_error(cc,bb)\n",
        "#    mm.append([X_plot_new[i], aa, cc, bb])\n",
        "print('total mse train:',mse_train/len(X))"
      ],
      "metadata": {
        "id": "HlvpAhIffsxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23\n",
        "# plot the result on train data\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_train=0\n",
        "predicted=model.predict(X)\n",
        "predicted3=models.predict(X)\n",
        "\n",
        "mm=[]\n",
        "for i in range(len(X)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "    aa=numpy.array(predicted[i])\n",
        "    bb=numpy.array(Y[i])\n",
        "    cc=numpy.array(predicted3[i])\n",
        "    ax0.set_title('Train Data')\n",
        "    ax0.plot(X_plot_new[i],aa,color='r',lw=1.5,label='NN Output',linestyle=':')\n",
        "    ax0.plot(X_plot_new[i],bb,color='b',marker='None',lw=1.5,markersize=1,label='Train Data')\n",
        "    ax0.plot(X_plot_new[i],cc,color='g',lw=1.5,label='NN Output',linestyle=':')\n",
        "    ax0.grid()\n",
        "    plt.legend([\"CWLSTM\",\"target\",\"RNN\"])\n",
        "    plt.show()\n",
        "#    mse_train+=mean_squared_error(bb,cc)\n",
        "    mm.append([X_plot_new[i],aa,bb,cc])\n",
        "#print('total mse train:',mse_train/len(X))"
      ],
      "metadata": {
        "id": "gSMuJm9OWSLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j, k , L in zip(mm[20][0].tolist(),mm[20][1].tolist(),mm[20][2].tolist(), mm[20][3].tolist()):\n",
        "  print(i, j[0], k[0], L[0])"
      ],
      "metadata": {
        "id": "Hk5pTR5ccjev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23\n",
        "# plot the result on train data\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_train=0\n",
        "predicted3=models.predict(X)\n",
        "predicted=model.predict(X)\n",
        "\n",
        "mm=[]\n",
        "for i in range(len(X)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "    cc=numpy.array(predicted3[i])\n",
        "    bb=numpy.array(Y[i])\n",
        "    aa=numpy.array(predicted[i])\n",
        "    ax0.set_title('Train Data')\n",
        "    aa=numpy.subtract(bb,aa)\n",
        "    aa=numpy.absolute(aa)\n",
        "    cc=numpy.subtract(bb,cc)\n",
        "    cc=numpy.absolute(cc)\n",
        "    ax0.plot(X_plot_new[i],aa,color='r',lw=2.5,label='NN Output',linestyle=':')\n",
        "    ax0.plot(X_plot_new[i],cc,color='g',lw=2.5,label='NN Output',linestyle=':')\n",
        "    ax0.grid()\n",
        "    plt.legend([\"CWLSTM\",\"RNN\"])\n",
        "    plt.show()\n",
        "#    mse_train+=mean_squared_error(bb,cc)\n",
        "    mm.append([X_plot_new[i],aa,cc])\n",
        "#print('total mse train:',mse_train/len(X))"
      ],
      "metadata": {
        "id": "zY03UINMq_Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j, k in zip(mm[20][0].tolist(),mm[20][1].tolist(),mm[20][2].tolist()):\n",
        "  print(i, j[0], k[0])"
      ],
      "metadata": {
        "id": "b1oD4nPjreDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEqFXmBixOIv"
      },
      "source": [
        "#22\n",
        "from inspect import CORO_CLOSED\n",
        "#21\n",
        "# plot the result on train data\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_train=0\n",
        "predicted=models.predict(X_test)\n",
        "#predicted2=model2.predict(X)\n",
        "#mm=[]\n",
        "for i in range(len(X_test)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "\n",
        "    bb=numpy.array(Y_test[i])\n",
        "    aa=numpy.array(predicted[i])\n",
        "#    aa=numpy.array(predicted2[i])\n",
        "    ax0.set_title('Test Data')\n",
        "#    ax0.plot(X_plot_new[i],aa,color='g',marker='None',lw=2,markersize=2,linestyle='-')\n",
        "    ax0.plot(X_plot_new_test[i],aa,color='r',marker='None',lw=1,markersize=2,linestyle='-')\n",
        "    ax0.plot(X_plot_new_test[i],bb,color='b',lw=1,label='Test Data',linestyle=':')\n",
        "\n",
        "\n",
        "    ax0.grid()\n",
        "    plt.legend([\"RNN\",\"Target Value\"])\n",
        "    plt.show()\n",
        "    mse_train+=mean_squared_error(aa,bb)\n",
        "#    mm.append([X_plot_new[i], aa, cc, bb])\n",
        "print('total mse test:',mse_train/len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22\n",
        "# plot the result on test data\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_test=0\n",
        "predicted=model.predict(X_test)\n",
        "#predicted2=models.predict(X_test)\n",
        "#mm=[]\n",
        "for i in range(len(X_test)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "\n",
        "    bb=numpy.array(Y_test[i])\n",
        "    cc=numpy.array(predicted[i])\n",
        "#    aa=numpy.array(predicted2[i])\n",
        "    ax0.set_title('Test Data')\n",
        "#    ax0.plot(X_plot_new_test[i],aa,color='g',lw=3,linestyle=':')\n",
        "    ax0.plot(X_plot_new_test[i],cc,color='r',lw=1,linestyle=':')\n",
        "    ax0.plot(X_plot_new_test[i],bb,color='b',lw=1,label='Test Data',linestyle='-')\n",
        "    ax0.grid()\n",
        "    plt.legend([\"CWLSTM\",\"Target Value\"])\n",
        "    plt.show()\n",
        "    mse_test+=mean_squared_error(cc,bb)\n",
        "#    mm.append([X_plot_new_test[i], aa,cc,bb])\n",
        "print('total mse test:',mse_test/len(X_test))"
      ],
      "metadata": {
        "id": "vFvVz62YgOSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22\n",
        "# plot the result on test data\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_test=0\n",
        "predicted3=models.predict(X_test)\n",
        "predicted=model.predict(X_test)\n",
        "mm=[]\n",
        "for i in range(len(X_test)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "    aa=numpy.array(predicted[i])\n",
        "    bb=numpy.array(Y_test[i])\n",
        "    cc=numpy.array(predicted3[i])\n",
        "    ax0.set_title('Test Data')\n",
        "    ax0.plot(X_plot_new_test[i],aa,color='g',lw=2.5,label='NN Output',linestyle=':')\n",
        "    ax0.plot(X_plot_new_test[i],bb,color='b',marker='None',lw=2.5,markersize=2,label='Test Data')\n",
        "    ax0.plot(X_plot_new_test[i],cc,color='r',lw=2.5,label='NN Output',linestyle=':')\n",
        "    ax0.grid()\n",
        "    plt.legend([\"CWLSTM\",\"target value\",\"RNN\"])\n",
        "    plt.show()\n",
        "#    mse_test+=mean_squared_error(bb,cc)\n",
        "    mm.append([X_plot_new_test[i],aa,bb,cc])\n",
        "#print('total mse test:',mse_test/len(X_test))"
      ],
      "metadata": {
        "id": "6nudNyPX16TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j, k , L in zip(mm[1][0].tolist(),mm[1][1].tolist(),mm[1][2].tolist(), mm[1][3].tolist()):\n",
        "  print(i, j[0], k[0], L[0])"
      ],
      "metadata": {
        "id": "H6eby5TxdmD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_test=0\n",
        "predicted=models.predict(X_test)\n",
        "predicted3=model.predict(X_test)\n",
        "mm=[]\n",
        "for i in range(len(X_test)):\n",
        "    fig = plt.figure(figsize=(11,7))\n",
        "    ax0 = fig.add_subplot(211)\n",
        "\n",
        "    aa=numpy.array(predicted[i])\n",
        "    bb=numpy.array(Y_test[i])\n",
        "    cc=numpy.array(predicted3[i])\n",
        "    ax0.set_title('Test Data')\n",
        "    aa=numpy.subtract(bb,aa)\n",
        "    aa=numpy.absolute(aa)\n",
        "    cc=numpy.subtract(bb,cc)\n",
        "    cc=numpy.absolute(cc)\n",
        "    ax0.plot(X_plot_new_test[i],aa,color='g',lw=1,label='NN Output',linestyle=':')\n",
        "    ax0.plot(X_plot_new_test[i],cc,color='r',lw=1,label='NN Output',linestyle=':')\n",
        "    ax0.grid()\n",
        "    plt.legend([\"CWLSTM\",\"RNN\"])\n",
        "    plt.show()\n",
        "#    mse_test+=mean_squared_error(bb,cc)\n",
        "    mm.append([X_plot_new_test[i],aa,cc])\n",
        "#print('total mse test:',mse_test/len(X_test))"
      ],
      "metadata": {
        "id": "VqJzkuPJrjJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j, k in zip(mm[1][0].tolist(),mm[1][1].tolist(),mm[1][2].tolist()):\n",
        "  print(i, j[0], k[0])"
      ],
      "metadata": {
        "id": "PHFh2NP_xufw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
